{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2cbc633b",
   "metadata": {},
   "source": [
    "### Importing Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27c663de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/macbookair/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/macbookair/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas: This librarie will used to create and work with dataframes.\n",
    "import pandas as pd \n",
    "# Matplotlib: Used to plot graphics. \n",
    "import matplotlib.pyplot as plt\n",
    "# Seaborn: Used to better style and iprove graphics. \n",
    "import seaborn as sns\n",
    "#Tweepy: Used to work with the Twitter API.\n",
    "import tweepy as tw\n",
    "#ConfigParser: Used to get credentials for the twitter API.\n",
    "import configparser as cp\n",
    "#NLTK its used to pre-proccess text and regex its used to filter that text.\n",
    "import nltk, re\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad6b3b",
   "metadata": {},
   "source": [
    "### Importing and authenticating API credentials from the config file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2191a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "config =  cp.ConfigParser()\n",
    "config.read(\"config.ini\")\n",
    "\n",
    "api_key = config[\"twitter\"][\"api_key\"]\n",
    "api_key_secret = config[\"twitter\"][\"api_key_secret\"]\n",
    "access_token = config[\"twitter\"][\"access_token\"]\n",
    "access_token_secret = config[\"twitter\"][\"access_token_secret\"]\n",
    "\n",
    "# Authentication\n",
    "\n",
    "auth = tw.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tw.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c462a2",
   "metadata": {},
   "source": [
    "### Funtions to work with in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4fd4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to perform data extraction from twitter.\n",
    "def scrape(words, date_since, numtweet):\n",
    "# We are using .Cursor() to search\n",
    "# through twitter for the required tweets.\n",
    "# The number of tweets can be\n",
    "# restricted using .items(number of tweets)\n",
    "    tweets = tw.Cursor(api.search_tweets,\n",
    "                               words, lang=\"en\",\n",
    "                               since_id=date_since,\n",
    "                               tweet_mode='extended').items(numtweet)\n",
    "# .Cursor() returns an iterable object. Each item in\n",
    "# the iterator has various attributes\n",
    "# that you can access to\n",
    "# get information about each tweet\n",
    "    list_tweets = [tweet for tweet in tweets]\n",
    " \n",
    "# we will iterate over each tweet in the\n",
    "# list for extracting information about each tweet\n",
    "    columns=['tweet_date','tweets']\n",
    "    data = []\n",
    "    for tweet in list_tweets:\n",
    "        tweet_date = tweet.created_at\n",
    "# Retweets can be distinguished by\n",
    "# a retweeted_status attribute,\n",
    "# in case it is an invalid reference,\n",
    "# except block will be executed\n",
    "        try:\n",
    "            tweets = tweet.retweeted_status.full_text\n",
    "        except AttributeError:\n",
    "            tweets = tweet.full_text\n",
    "            data.append([tweet_date, tweets])\n",
    "# Creating DataFrame using pandas\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2a926f",
   "metadata": {},
   "source": [
    "### Getting the data from twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0990983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = scrape(\"Tesla\", 2022-0o1-0o1, 100)\n",
    "ford = scrape(\"Ford\", 2022-0o1-0o1, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a5e3b6",
   "metadata": {},
   "source": [
    "### Preproccessing the data for further analisys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43d7b0b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'apple' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-134c3f34d739>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGrouper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tweet_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1D'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mapple\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'apple' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "apple['tweets'] = apple['tweets'].apply(preprocess_text)\n",
    "apple.groupby(pd.Grouper(key='tweet_date', axis=0, freq='1D', sort=True)).concat()\n",
    "apple.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bd4fd867a48befa8578228ebda43b7fca3d2cb04ef051ceb4c0ba90b2504b0aa"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
